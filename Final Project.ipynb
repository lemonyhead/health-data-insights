{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c48a5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the CSV file to \"Heart_Disease_Mortality\" bc the name is WAY TOO LONG\n",
    "#Open in Google Collaboratory, save changes frequently, and we cannot use the file at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fdd55893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as random\n",
    "import pandas as pd\n",
    "import json,csv, requests, re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aac24ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This the CSV stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bf5fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Avg_Num_Deaths  Percent Total %\n",
      "LocationAbbr                                 \n",
      "AK                318.396517         1.698614\n",
      "AL                452.940996         2.416396\n",
      "AR                447.272996         2.386157\n",
      "AS                343.533333         1.832716\n",
      "AZ                272.962357         1.456227\n",
      "CA                298.068489         1.590166\n",
      "CO                247.797399         1.321975\n",
      "CT                255.655882         1.363899\n",
      "DC                306.178571         1.633432\n",
      "DE                270.705172         1.444185\n",
      "FL                286.450326         1.528184\n",
      "GA                380.160799         2.028120\n",
      "GU                529.800000         2.826431\n",
      "HI                300.981707         1.605708\n",
      "IA                329.146016         1.755962\n",
      "ID                278.923204         1.488028\n",
      "IL                343.175380         1.830807\n",
      "IN                354.644851         1.891995\n",
      "KS                339.465344         1.811014\n",
      "KY                431.482062         2.301914\n",
      "LA                452.033086         2.411552\n",
      "MA                235.640385         1.257118\n",
      "MD                305.678086         1.630762\n",
      "ME                306.322321         1.634199\n",
      "MI                373.413155         1.992122\n",
      "MN                263.462181         1.405545\n",
      "MO                406.578002         2.169054\n",
      "MP                379.133333         2.022639\n",
      "MS                495.518182         2.643541\n",
      "MT                349.521053         1.864660\n",
      "NC                318.169751         1.697404\n",
      "ND                336.993575         1.797827\n",
      "NE                299.904294         1.599960\n",
      "NH                250.927451         1.338673\n",
      "NJ                287.223123         1.532307\n",
      "NM                299.150000         1.595936\n",
      "NV                342.786873         1.828734\n",
      "NY                324.855941         1.733074\n",
      "OH                358.969450         1.915067\n",
      "OK                451.891615         2.410797\n",
      "OR                252.234354         1.345645\n",
      "PA                333.401166         1.778662\n",
      "PR                222.775527         1.188485\n",
      "RI                260.948276         1.392133\n",
      "SC                349.207394         1.862987\n",
      "SD                336.514409         1.795271\n",
      "TN                424.682379         2.265639\n",
      "TX                362.380342         1.933263\n",
      "US                301.700000         1.609540\n",
      "UT                273.006774         1.456464\n",
      "VA                327.246877         1.745830\n",
      "VI                 88.300000         0.471072\n",
      "VT                305.188421         1.628150\n",
      "WA                271.518182         1.448523\n",
      "WI                309.550390         1.651421\n",
      "WV                386.078851         2.059693\n",
      "WY                313.842512         1.674319\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd  #already imported delete later\n",
    "df = pd.read_csv('Heart_Disease_Mortality.csv')\n",
    "  \n",
    "#removes the columns\n",
    "df.drop('Year', inplace=True, axis=1)\n",
    "df.drop('GeographicLevel', inplace=True, axis=1)\n",
    "df.drop('DataSource', inplace=True, axis=1)\n",
    "df.drop('Class', inplace=True, axis=1)\n",
    "df.drop('Topic', inplace=True, axis=1)\n",
    "df.drop('Data_Value_Unit', inplace=True, axis=1)\n",
    "df.drop('Data_Value_Type', inplace=True, axis=1)\n",
    "df.drop('Data_Value_Footnote_Symbol', inplace=True, axis=1)\n",
    "df.drop('Data_Value_Footnote', inplace=True, axis=1)\n",
    "df.drop('StratificationCategory1', inplace=True, axis=1)\n",
    "df.drop('Stratification1', inplace=True, axis=1)\n",
    "df.drop('StratificationCategory2', inplace=True, axis=1)\n",
    "df.drop('Stratification2', inplace=True, axis=1)\n",
    "df.drop('TopicID', inplace=True, axis=1)\n",
    "df.drop('LocationID', inplace=True, axis=1)\n",
    "df.drop('Location 1', inplace=True, axis=1)\n",
    "df.drop('LocationDesc', inplace=True, axis=1)\n",
    "\n",
    "#getting rid of the columns with np.nan in the 'Data_Value' column\n",
    "df = df[df['Data_Value'].notna()]\n",
    "\n",
    "#sorting the datavalues by 'LocationAbbr'\n",
    "df.sort_values(by=['LocationAbbr'], ascending=True, inplace = True)\n",
    "\n",
    "#resets the index of each row to increase from 0 to the number of rows\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#Finding the average number of deaths due to Heart Disease per state/territory per 100,000 people\n",
    "df = df.groupby(['LocationAbbr']).agg({'Data_Value': 'mean'})\n",
    "\n",
    "#Rename the Data_Value column to Avg_Num_Deaths\n",
    "df.rename(columns = {'Data_Value':'Avg_Num_Deaths'}, inplace = True)\n",
    "\n",
    "#Finding the total number of deaths within in the US states and territories, this can be used to find the percentage that each state makes up\n",
    "total = 0\n",
    "for row in avg_deaths['Avg_Num_Deaths']:\n",
    "    total += row\n",
    "\n",
    "#Adding a new column to avg_deaths that represents the percentage of heart disease deaths in the country that fall within the state\n",
    "percentage  = []\n",
    "for row in df['Avg_Num_Deaths']:\n",
    "    percentage.append(row/total*100)\n",
    "df['Percent Total %'] = percentage\n",
    "\n",
    "#Writing the dataframe to an output CSV file\n",
    "df.to_csv('heart_disease_output.csv', index=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e5bf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the BeautifulSoup Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bb698d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['States, district, & territories', 'Obesity rank', 'Obese adults (mid-2000s)', 'Obese adults (2020)', 'Overweight (incl. obese) adults(mid-2000s)', 'Obese children and adolescents(mid-2000s)'], ['Alabama', '5', '30.1%', '36.3%', '65.4%', '16.7%'], ['Alaska', '9', '27.3%', '34.2%', '64.5%', '11.1%'], ['American Samoa', 'n/a', 'n/a', '75%', '95%', '35%'], ['Arizona', '30', '23.3%', '29.5%', '59.5%', '12.2%'], ['Arkansas', '7', '28.1%', '35.0%', '64.7%', '16.4%'], ['California', '48', '23.1%', '25.1%', '59.4%', '13.2%'], ['Colorado', '51', '21.0%', '22.6%', '55.0%', '9.9%'], ['Connecticut', '42', '20.8%', '26.9%', '58.7%', '12.3%'], ['Delaware', '23', '25.9%', '31.8%', '63.9%', '22.8%'], ['District of Columbia', '50', '22.1%', '23.0%', '55.0%', '14.8%'], ['Florida', '35', '23.3%', '28.4%', '60.8%', '14.4%'], ['Georgia', '24', '27.5%', '31.6%', '63.3%', '16.4%'], ['Guam', 'n/a', 'n/a', '28.3%', 'n/a', '22%'], ['Hawaii', '49', '20.7%', '23.8%', '55.3%', '13.3%'], ['Idaho', '32', '24.6%', '29.3%', '61.4%', '10.1%'], ['Illinois', '27', '25.3%', '31.1%', '61.8%', '15.8%'], ['Indiana', '12', '27.5%', '33.6%', '62.8%', '15.6%'], ['Iowa', '4', '26.3%', '36.4%', '63.4%', '12.5%'], ['Kansas', '18', '25.8%', '32.4%', '62.3%', '14.0%'], ['Kentucky', '8', '28.4%', '34.3%', '66.8%', '20.6%'], ['Louisiana', '6', '29.5%', '36.2%', '64.2%', '17.2%'], ['Maine', '33', '23.7%', '29.1%', '60.8%', '12.7%'], ['Maryland', '26', '25.2%', '31.3%', '61.5%', '13.3%'], ['Massachusetts', '44', '20.9%', '25.9%', '56.8%', '13.6%'], ['Michigan', '19', '27.7%', '32.3%', '63.9%', '14.5%'], ['Minnesota', '35', '24.8%', '28.4%', '61.9%', '10.1%'], ['Mississippi', '2', '34.4%', '37.3%', '67.4%', '17.8%'], ['Missouri', '17', '27.4%', '32.5%', '63.3%', '15.6%'], ['Montana', '46', '21.7%', '25.3%', '59.6%', '11.1%'], ['Nebraska', '15', '26.5%', '32.8%', '63.9%', '11.9%'], ['Nevada', '43', '23.6%', '26.7%', '61.8%', '12.4%'], ['New Hampshire', '38', '23.6%', '28.1%', '60.8%', '12.9%'], ['New Jersey', '41', '22.9%', '27.3%', '60.5%', '13.7%'], ['New Mexico', '35', '23.3%', '28.4%', '60.3%', '16.8%'], ['New York', '45', '23.5%', '25.7%', '60.0%', '15.3%'], ['North Carolina', '20', '27.1%', '32.1%', '63.4%', '19.3%'], ['North Dakota', '13', '25.9%', '33.2%', '64.5%', '12.1%'], ['Northern Mariana Islands', 'n/a', 'n/a', 'n/a', 'n/a', '16%'], ['Ohio', '11', '26.9%', '33.8%', '63.3%', '14.2%'], ['Oklahoma', '3', '28.1%', '36.5%', '64.2%', '15.4%'], ['Oregon', '31', '25.0%', '29.4%', '60.8%', '14.1%'], ['Pennsylvania', '24', '25.7%', '31.6%', '61.9%', '13.3%'], ['Puerto Rico', 'n/a', 'n/a', '30.7%', 'n/a', '26%'], ['Rhode Island', '29', '21.4%', '30.0%', '60.4%', '11.9%'], ['South Carolina', '10', '29.2%', '34.1%', '65.1%', '18.9%'], ['South Dakota', '22', '26.1%', '31.9%', '64.2%', '12.1%'], ['Tennessee', '15', '29.0%', '32.8%', '65.0%', '20.0%'], ['Texas', '14', '27.2%', '33.0%', '64.1%', '19.1%'], ['Utah', '46', '21.8%', '25.3%', '56.4%', '8.5%'], ['Vermont', '40', '21.1%', '27.6%', '56.9%', '11.3%'], ['Virgin Islands (U.S.)', 'n/a', 'n/a', '32.5%', 'n/a', 'n/a'], ['Virginia', '28', '25.2%', '30.1%', '61.6%', '13.8%'], ['Washington', '39', '24.5%', '27.7%', '60.7%', '10.8%'], ['West Virginia', '1', '30.6%', '38.1%', '66.8%', '20.9%'], ['Wisconsin', '21', '25.5%', '32.0%', '62.4%', '13.5%'], ['Wyoming', '34', '24.0%', '28.8%', '61.7%', '8.7%']]\n"
     ]
    }
   ],
   "source": [
    "#Url of the website with the table\n",
    "r = requests.get(\"https://en.wikipedia.org/wiki/Obesity_in_the_United_States\")\n",
    "\n",
    "#Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\n",
    "#Find the table tag\n",
    "table = soup.find('table',{'class':'wikitable sortable'})\n",
    "\n",
    "#This is the list where the final data will be appended\n",
    "output_list = []\n",
    "\n",
    "#Find the header row and getting the column headers (tr), appending it to the final list\n",
    "header_row = table.find('tr')\n",
    "headers = header_row.find_all('th')\n",
    "header_info = []\n",
    "for header in headers:\n",
    "    info = (header.get_text().strip())\n",
    "    if \"[\" in info:\n",
    "        info = info[:-4]\n",
    "    if \"[\" in info:\n",
    "        info = info[:-4]\n",
    "    header_info.append(info)\n",
    "output_list.append(header_info)\n",
    "\n",
    "#Find all row tags (tr) in the table\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "#This is the regex match text\n",
    "regex_replace = re.compile(r'\\[.*?\\]')\n",
    "\n",
    "#Iterate over each row and getting the data from each cell (td)\n",
    "for row in rows[1:]: #skipping the header row which would otherwise be blank\n",
    "    info = row.find_all('td')\n",
    "    row_data = []\n",
    "    for item in info:\n",
    "        cleaned_data = (item.get_text().strip())\n",
    "        if \"[\" in cleaned_data:\n",
    "            cleaned_data = cleaned_data[:-4]\n",
    "        if \"[\" in cleaned_data:\n",
    "            cleaned_data = cleaned_data[:-4]\n",
    "        row_data.append(cleaned_data)\n",
    "    output_list.append(row_data)\n",
    "\n",
    "#Replace the '-' with n/a to better represent the meaning of '-'\n",
    "for lists in output_list:\n",
    "    x+=1\n",
    "    for i in range(len(lists)):\n",
    "        if lists[i] == '—':\n",
    "            lists[i] = \"n/a\"\n",
    "\n",
    "print(output_list)\n",
    "#Writing the output_list to an output_file using csv\n",
    "#opening an output file for writing named US_Obesity\n",
    "with open('US_Obesity.csv', 'w', newline='') as output:\n",
    "    writer = csv.writer(output)\n",
    "    writer.writerows(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "22948517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inconsistencies to Note\n",
    "#CSV: Removed all the rows that had np.nan as the data value\n",
    "#BeautifulSoup: Since this is a wikipedia page, there are footnotes. Those were removed using string methods. \n",
    "#BeautifulSoup: Replaced the '-' in the data set with \"n/a\" to better represent what the absent values represent. Additionally, by not removing any of the rows, there are an equal number of states/territories (57) in both the wikipedia dataset and the csv dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
